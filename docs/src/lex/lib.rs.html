<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `lex&#x2F;src&#x2F;lib.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>lib.rs - source</title><link rel="stylesheet" type="text/css" href="../../normalize.css"><link rel="stylesheet" type="text/css" href="../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" type="text/css" href="../../light.css"  id="themeStyle"><link rel="stylesheet" type="text/css" href="../../dark.css" disabled ><link rel="stylesheet" type="text/css" href="../../ayu.css" disabled ><script id="default-settings" ></script><script src="../../storage.js"></script><script src="../../crates.js"></script><script defer src="../../main.js"></script><script defer src="../../source-script.js"></script><script defer src="../../source-files.js"></script>
    <noscript><link rel="stylesheet" href="../../noscript.css"></noscript><link rel="alternate icon" type="image/png" href="../../favicon-16x16.png"><link rel="alternate icon" type="image/png" href="../../favicon-32x32.png"><link rel="icon" type="image/svg+xml" href="../../favicon.svg"><style type="text/css">#crate-search{background-image:url("../../down-arrow.svg");}</style></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="sidebar-menu" role="button">&#9776;</div><a href='../../lex/index.html'><div class='logo-container rust-logo'><img src='../../rust-logo.png' alt='logo'></div></a></nav><div class="theme-picker"><button id="theme-picker" aria-label="Pick another theme!" aria-haspopup="menu" title="themes"><img width="18" height="18" alt="Pick another theme!" src="../../brush.svg"></button><div id="theme-choices" role="menu"></div></div><nav class="sub"><form class="search-form"><div class="search-container"><div><select id="crate-search"><option value="All crates">All crates</option></select><input class="search-input" name="search" autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"></div><button type="button" id="help-button" title="help">?</button><a id="settings-menu" href="../../settings.html" title="settings"><img width="18" height="18" alt="Change settings" src="../../wheel.svg"></a></div></form></nav><section id="main" class="content"><div class="example-wrap"><pre class="line-numbers"><span id="1">  1</span>
<span id="2">  2</span>
<span id="3">  3</span>
<span id="4">  4</span>
<span id="5">  5</span>
<span id="6">  6</span>
<span id="7">  7</span>
<span id="8">  8</span>
<span id="9">  9</span>
<span id="10"> 10</span>
<span id="11"> 11</span>
<span id="12"> 12</span>
<span id="13"> 13</span>
<span id="14"> 14</span>
<span id="15"> 15</span>
<span id="16"> 16</span>
<span id="17"> 17</span>
<span id="18"> 18</span>
<span id="19"> 19</span>
<span id="20"> 20</span>
<span id="21"> 21</span>
<span id="22"> 22</span>
<span id="23"> 23</span>
<span id="24"> 24</span>
<span id="25"> 25</span>
<span id="26"> 26</span>
<span id="27"> 27</span>
<span id="28"> 28</span>
<span id="29"> 29</span>
<span id="30"> 30</span>
<span id="31"> 31</span>
<span id="32"> 32</span>
<span id="33"> 33</span>
<span id="34"> 34</span>
<span id="35"> 35</span>
<span id="36"> 36</span>
<span id="37"> 37</span>
<span id="38"> 38</span>
<span id="39"> 39</span>
<span id="40"> 40</span>
<span id="41"> 41</span>
<span id="42"> 42</span>
<span id="43"> 43</span>
<span id="44"> 44</span>
<span id="45"> 45</span>
<span id="46"> 46</span>
<span id="47"> 47</span>
<span id="48"> 48</span>
<span id="49"> 49</span>
<span id="50"> 50</span>
<span id="51"> 51</span>
<span id="52"> 52</span>
<span id="53"> 53</span>
<span id="54"> 54</span>
<span id="55"> 55</span>
<span id="56"> 56</span>
<span id="57"> 57</span>
<span id="58"> 58</span>
<span id="59"> 59</span>
<span id="60"> 60</span>
<span id="61"> 61</span>
<span id="62"> 62</span>
<span id="63"> 63</span>
<span id="64"> 64</span>
<span id="65"> 65</span>
<span id="66"> 66</span>
<span id="67"> 67</span>
<span id="68"> 68</span>
<span id="69"> 69</span>
<span id="70"> 70</span>
<span id="71"> 71</span>
<span id="72"> 72</span>
<span id="73"> 73</span>
<span id="74"> 74</span>
<span id="75"> 75</span>
<span id="76"> 76</span>
<span id="77"> 77</span>
<span id="78"> 78</span>
<span id="79"> 79</span>
<span id="80"> 80</span>
<span id="81"> 81</span>
<span id="82"> 82</span>
<span id="83"> 83</span>
<span id="84"> 84</span>
<span id="85"> 85</span>
<span id="86"> 86</span>
<span id="87"> 87</span>
<span id="88"> 88</span>
<span id="89"> 89</span>
<span id="90"> 90</span>
<span id="91"> 91</span>
<span id="92"> 92</span>
<span id="93"> 93</span>
<span id="94"> 94</span>
<span id="95"> 95</span>
<span id="96"> 96</span>
<span id="97"> 97</span>
<span id="98"> 98</span>
<span id="99"> 99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
<span id="248">248</span>
<span id="249">249</span>
<span id="250">250</span>
<span id="251">251</span>
<span id="252">252</span>
<span id="253">253</span>
<span id="254">254</span>
<span id="255">255</span>
<span id="256">256</span>
<span id="257">257</span>
<span id="258">258</span>
<span id="259">259</span>
<span id="260">260</span>
<span id="261">261</span>
<span id="262">262</span>
<span id="263">263</span>
<span id="264">264</span>
<span id="265">265</span>
<span id="266">266</span>
<span id="267">267</span>
<span id="268">268</span>
<span id="269">269</span>
<span id="270">270</span>
<span id="271">271</span>
<span id="272">272</span>
<span id="273">273</span>
<span id="274">274</span>
<span id="275">275</span>
<span id="276">276</span>
<span id="277">277</span>
<span id="278">278</span>
<span id="279">279</span>
<span id="280">280</span>
<span id="281">281</span>
<span id="282">282</span>
<span id="283">283</span>
<span id="284">284</span>
<span id="285">285</span>
<span id="286">286</span>
<span id="287">287</span>
<span id="288">288</span>
<span id="289">289</span>
<span id="290">290</span>
<span id="291">291</span>
<span id="292">292</span>
<span id="293">293</span>
<span id="294">294</span>
<span id="295">295</span>
<span id="296">296</span>
<span id="297">297</span>
<span id="298">298</span>
<span id="299">299</span>
<span id="300">300</span>
<span id="301">301</span>
<span id="302">302</span>
<span id="303">303</span>
<span id="304">304</span>
<span id="305">305</span>
<span id="306">306</span>
<span id="307">307</span>
<span id="308">308</span>
<span id="309">309</span>
<span id="310">310</span>
<span id="311">311</span>
<span id="312">312</span>
<span id="313">313</span>
<span id="314">314</span>
<span id="315">315</span>
<span id="316">316</span>
<span id="317">317</span>
<span id="318">318</span>
<span id="319">319</span>
<span id="320">320</span>
<span id="321">321</span>
<span id="322">322</span>
<span id="323">323</span>
<span id="324">324</span>
<span id="325">325</span>
<span id="326">326</span>
<span id="327">327</span>
<span id="328">328</span>
<span id="329">329</span>
<span id="330">330</span>
<span id="331">331</span>
<span id="332">332</span>
<span id="333">333</span>
<span id="334">334</span>
<span id="335">335</span>
<span id="336">336</span>
<span id="337">337</span>
<span id="338">338</span>
<span id="339">339</span>
<span id="340">340</span>
<span id="341">341</span>
<span id="342">342</span>
<span id="343">343</span>
<span id="344">344</span>
<span id="345">345</span>
<span id="346">346</span>
<span id="347">347</span>
<span id="348">348</span>
<span id="349">349</span>
<span id="350">350</span>
<span id="351">351</span>
<span id="352">352</span>
<span id="353">353</span>
<span id="354">354</span>
<span id="355">355</span>
<span id="356">356</span>
<span id="357">357</span>
<span id="358">358</span>
<span id="359">359</span>
<span id="360">360</span>
<span id="361">361</span>
<span id="362">362</span>
<span id="363">363</span>
<span id="364">364</span>
<span id="365">365</span>
<span id="366">366</span>
<span id="367">367</span>
<span id="368">368</span>
<span id="369">369</span>
<span id="370">370</span>
<span id="371">371</span>
<span id="372">372</span>
<span id="373">373</span>
<span id="374">374</span>
<span id="375">375</span>
<span id="376">376</span>
<span id="377">377</span>
<span id="378">378</span>
<span id="379">379</span>
<span id="380">380</span>
<span id="381">381</span>
<span id="382">382</span>
<span id="383">383</span>
<span id="384">384</span>
<span id="385">385</span>
<span id="386">386</span>
<span id="387">387</span>
<span id="388">388</span>
<span id="389">389</span>
<span id="390">390</span>
<span id="391">391</span>
<span id="392">392</span>
<span id="393">393</span>
<span id="394">394</span>
<span id="395">395</span>
<span id="396">396</span>
<span id="397">397</span>
<span id="398">398</span>
<span id="399">399</span>
<span id="400">400</span>
<span id="401">401</span>
<span id="402">402</span>
<span id="403">403</span>
<span id="404">404</span>
<span id="405">405</span>
<span id="406">406</span>
<span id="407">407</span>
<span id="408">408</span>
<span id="409">409</span>
<span id="410">410</span>
<span id="411">411</span>
<span id="412">412</span>
<span id="413">413</span>
<span id="414">414</span>
<span id="415">415</span>
<span id="416">416</span>
<span id="417">417</span>
<span id="418">418</span>
<span id="419">419</span>
<span id="420">420</span>
<span id="421">421</span>
<span id="422">422</span>
<span id="423">423</span>
<span id="424">424</span>
<span id="425">425</span>
<span id="426">426</span>
<span id="427">427</span>
<span id="428">428</span>
<span id="429">429</span>
<span id="430">430</span>
<span id="431">431</span>
<span id="432">432</span>
<span id="433">433</span>
<span id="434">434</span>
<span id="435">435</span>
<span id="436">436</span>
<span id="437">437</span>
<span id="438">438</span>
<span id="439">439</span>
<span id="440">440</span>
<span id="441">441</span>
<span id="442">442</span>
<span id="443">443</span>
<span id="444">444</span>
<span id="445">445</span>
<span id="446">446</span>
<span id="447">447</span>
<span id="448">448</span>
<span id="449">449</span>
<span id="450">450</span>
<span id="451">451</span>
<span id="452">452</span>
<span id="453">453</span>
<span id="454">454</span>
<span id="455">455</span>
<span id="456">456</span>
<span id="457">457</span>
<span id="458">458</span>
<span id="459">459</span>
<span id="460">460</span>
<span id="461">461</span>
<span id="462">462</span>
<span id="463">463</span>
<span id="464">464</span>
<span id="465">465</span>
<span id="466">466</span>
<span id="467">467</span>
<span id="468">468</span>
<span id="469">469</span>
<span id="470">470</span>
<span id="471">471</span>
<span id="472">472</span>
<span id="473">473</span>
<span id="474">474</span>
<span id="475">475</span>
<span id="476">476</span>
<span id="477">477</span>
<span id="478">478</span>
<span id="479">479</span>
<span id="480">480</span>
<span id="481">481</span>
<span id="482">482</span>
<span id="483">483</span>
<span id="484">484</span>
<span id="485">485</span>
<span id="486">486</span>
<span id="487">487</span>
<span id="488">488</span>
<span id="489">489</span>
<span id="490">490</span>
<span id="491">491</span>
<span id="492">492</span>
<span id="493">493</span>
<span id="494">494</span>
<span id="495">495</span>
<span id="496">496</span>
<span id="497">497</span>
<span id="498">498</span>
<span id="499">499</span>
<span id="500">500</span>
<span id="501">501</span>
<span id="502">502</span>
<span id="503">503</span>
<span id="504">504</span>
<span id="505">505</span>
<span id="506">506</span>
<span id="507">507</span>
<span id="508">508</span>
<span id="509">509</span>
<span id="510">510</span>
<span id="511">511</span>
<span id="512">512</span>
<span id="513">513</span>
<span id="514">514</span>
<span id="515">515</span>
<span id="516">516</span>
<span id="517">517</span>
<span id="518">518</span>
<span id="519">519</span>
<span id="520">520</span>
<span id="521">521</span>
<span id="522">522</span>
<span id="523">523</span>
<span id="524">524</span>
<span id="525">525</span>
<span id="526">526</span>
<span id="527">527</span>
<span id="528">528</span>
<span id="529">529</span>
<span id="530">530</span>
<span id="531">531</span>
<span id="532">532</span>
<span id="533">533</span>
<span id="534">534</span>
<span id="535">535</span>
<span id="536">536</span>
<span id="537">537</span>
<span id="538">538</span>
<span id="539">539</span>
<span id="540">540</span>
<span id="541">541</span>
<span id="542">542</span>
<span id="543">543</span>
<span id="544">544</span>
<span id="545">545</span>
<span id="546">546</span>
<span id="547">547</span>
<span id="548">548</span>
<span id="549">549</span>
<span id="550">550</span>
<span id="551">551</span>
<span id="552">552</span>
<span id="553">553</span>
<span id="554">554</span>
<span id="555">555</span>
<span id="556">556</span>
<span id="557">557</span>
<span id="558">558</span>
<span id="559">559</span>
<span id="560">560</span>
<span id="561">561</span>
<span id="562">562</span>
<span id="563">563</span>
<span id="564">564</span>
<span id="565">565</span>
<span id="566">566</span>
<span id="567">567</span>
<span id="568">568</span>
<span id="569">569</span>
<span id="570">570</span>
<span id="571">571</span>
<span id="572">572</span>
<span id="573">573</span>
<span id="574">574</span>
<span id="575">575</span>
<span id="576">576</span>
<span id="577">577</span>
<span id="578">578</span>
<span id="579">579</span>
<span id="580">580</span>
<span id="581">581</span>
<span id="582">582</span>
<span id="583">583</span>
<span id="584">584</span>
<span id="585">585</span>
<span id="586">586</span>
<span id="587">587</span>
<span id="588">588</span>
<span id="589">589</span>
<span id="590">590</span>
<span id="591">591</span>
<span id="592">592</span>
<span id="593">593</span>
<span id="594">594</span>
<span id="595">595</span>
<span id="596">596</span>
<span id="597">597</span>
<span id="598">598</span>
<span id="599">599</span>
<span id="600">600</span>
<span id="601">601</span>
<span id="602">602</span>
<span id="603">603</span>
<span id="604">604</span>
<span id="605">605</span>
<span id="606">606</span>
<span id="607">607</span>
<span id="608">608</span>
<span id="609">609</span>
<span id="610">610</span>
<span id="611">611</span>
<span id="612">612</span>
<span id="613">613</span>
<span id="614">614</span>
<span id="615">615</span>
<span id="616">616</span>
<span id="617">617</span>
<span id="618">618</span>
<span id="619">619</span>
<span id="620">620</span>
<span id="621">621</span>
<span id="622">622</span>
<span id="623">623</span>
<span id="624">624</span>
<span id="625">625</span>
<span id="626">626</span>
<span id="627">627</span>
<span id="628">628</span>
<span id="629">629</span>
<span id="630">630</span>
<span id="631">631</span>
<span id="632">632</span>
<span id="633">633</span>
<span id="634">634</span>
<span id="635">635</span>
<span id="636">636</span>
<span id="637">637</span>
<span id="638">638</span>
<span id="639">639</span>
<span id="640">640</span>
<span id="641">641</span>
<span id="642">642</span>
<span id="643">643</span>
<span id="644">644</span>
<span id="645">645</span>
<span id="646">646</span>
<span id="647">647</span>
<span id="648">648</span>
<span id="649">649</span>
<span id="650">650</span>
<span id="651">651</span>
<span id="652">652</span>
<span id="653">653</span>
<span id="654">654</span>
<span id="655">655</span>
<span id="656">656</span>
<span id="657">657</span>
<span id="658">658</span>
<span id="659">659</span>
<span id="660">660</span>
<span id="661">661</span>
<span id="662">662</span>
<span id="663">663</span>
<span id="664">664</span>
<span id="665">665</span>
<span id="666">666</span>
<span id="667">667</span>
<span id="668">668</span>
<span id="669">669</span>
<span id="670">670</span>
<span id="671">671</span>
<span id="672">672</span>
<span id="673">673</span>
<span id="674">674</span>
<span id="675">675</span>
<span id="676">676</span>
<span id="677">677</span>
<span id="678">678</span>
<span id="679">679</span>
<span id="680">680</span>
<span id="681">681</span>
<span id="682">682</span>
<span id="683">683</span>
<span id="684">684</span>
<span id="685">685</span>
<span id="686">686</span>
<span id="687">687</span>
<span id="688">688</span>
<span id="689">689</span>
<span id="690">690</span>
<span id="691">691</span>
<span id="692">692</span>
<span id="693">693</span>
<span id="694">694</span>
<span id="695">695</span>
<span id="696">696</span>
<span id="697">697</span>
<span id="698">698</span>
<span id="699">699</span>
<span id="700">700</span>
<span id="701">701</span>
<span id="702">702</span>
<span id="703">703</span>
<span id="704">704</span>
<span id="705">705</span>
<span id="706">706</span>
<span id="707">707</span>
<span id="708">708</span>
<span id="709">709</span>
<span id="710">710</span>
<span id="711">711</span>
<span id="712">712</span>
<span id="713">713</span>
<span id="714">714</span>
<span id="715">715</span>
<span id="716">716</span>
<span id="717">717</span>
<span id="718">718</span>
<span id="719">719</span>
<span id="720">720</span>
<span id="721">721</span>
<span id="722">722</span>
<span id="723">723</span>
<span id="724">724</span>
<span id="725">725</span>
<span id="726">726</span>
<span id="727">727</span>
<span id="728">728</span>
<span id="729">729</span>
<span id="730">730</span>
<span id="731">731</span>
<span id="732">732</span>
<span id="733">733</span>
<span id="734">734</span>
<span id="735">735</span>
<span id="736">736</span>
<span id="737">737</span>
<span id="738">738</span>
<span id="739">739</span>
<span id="740">740</span>
<span id="741">741</span>
<span id="742">742</span>
<span id="743">743</span>
<span id="744">744</span>
<span id="745">745</span>
<span id="746">746</span>
<span id="747">747</span>
<span id="748">748</span>
<span id="749">749</span>
<span id="750">750</span>
<span id="751">751</span>
<span id="752">752</span>
<span id="753">753</span>
<span id="754">754</span>
<span id="755">755</span>
<span id="756">756</span>
<span id="757">757</span>
<span id="758">758</span>
<span id="759">759</span>
<span id="760">760</span>
<span id="761">761</span>
<span id="762">762</span>
<span id="763">763</span>
<span id="764">764</span>
<span id="765">765</span>
<span id="766">766</span>
<span id="767">767</span>
<span id="768">768</span>
<span id="769">769</span>
<span id="770">770</span>
<span id="771">771</span>
<span id="772">772</span>
<span id="773">773</span>
<span id="774">774</span>
<span id="775">775</span>
<span id="776">776</span>
<span id="777">777</span>
<span id="778">778</span>
<span id="779">779</span>
<span id="780">780</span>
<span id="781">781</span>
<span id="782">782</span>
<span id="783">783</span>
<span id="784">784</span>
<span id="785">785</span>
<span id="786">786</span>
<span id="787">787</span>
<span id="788">788</span>
<span id="789">789</span>
<span id="790">790</span>
<span id="791">791</span>
<span id="792">792</span>
<span id="793">793</span>
<span id="794">794</span>
<span id="795">795</span>
<span id="796">796</span>
<span id="797">797</span>
<span id="798">798</span>
<span id="799">799</span>
<span id="800">800</span>
<span id="801">801</span>
<span id="802">802</span>
<span id="803">803</span>
<span id="804">804</span>
<span id="805">805</span>
<span id="806">806</span>
<span id="807">807</span>
<span id="808">808</span>
<span id="809">809</span>
<span id="810">810</span>
<span id="811">811</span>
<span id="812">812</span>
<span id="813">813</span>
<span id="814">814</span>
<span id="815">815</span>
<span id="816">816</span>
<span id="817">817</span>
<span id="818">818</span>
<span id="819">819</span>
<span id="820">820</span>
<span id="821">821</span>
<span id="822">822</span>
<span id="823">823</span>
<span id="824">824</span>
<span id="825">825</span>
<span id="826">826</span>
<span id="827">827</span>
<span id="828">828</span>
<span id="829">829</span>
<span id="830">830</span>
<span id="831">831</span>
<span id="832">832</span>
<span id="833">833</span>
<span id="834">834</span>
<span id="835">835</span>
<span id="836">836</span>
<span id="837">837</span>
<span id="838">838</span>
<span id="839">839</span>
<span id="840">840</span>
<span id="841">841</span>
<span id="842">842</span>
<span id="843">843</span>
<span id="844">844</span>
<span id="845">845</span>
<span id="846">846</span>
<span id="847">847</span>
<span id="848">848</span>
<span id="849">849</span>
<span id="850">850</span>
<span id="851">851</span>
<span id="852">852</span>
<span id="853">853</span>
<span id="854">854</span>
<span id="855">855</span>
<span id="856">856</span>
<span id="857">857</span>
<span id="858">858</span>
<span id="859">859</span>
<span id="860">860</span>
<span id="861">861</span>
<span id="862">862</span>
<span id="863">863</span>
<span id="864">864</span>
<span id="865">865</span>
<span id="866">866</span>
<span id="867">867</span>
<span id="868">868</span>
<span id="869">869</span>
<span id="870">870</span>
<span id="871">871</span>
<span id="872">872</span>
<span id="873">873</span>
<span id="874">874</span>
<span id="875">875</span>
<span id="876">876</span>
<span id="877">877</span>
<span id="878">878</span>
<span id="879">879</span>
<span id="880">880</span>
<span id="881">881</span>
<span id="882">882</span>
<span id="883">883</span>
<span id="884">884</span>
<span id="885">885</span>
<span id="886">886</span>
<span id="887">887</span>
<span id="888">888</span>
<span id="889">889</span>
<span id="890">890</span>
<span id="891">891</span>
<span id="892">892</span>
<span id="893">893</span>
<span id="894">894</span>
<span id="895">895</span>
<span id="896">896</span>
<span id="897">897</span>
<span id="898">898</span>
<span id="899">899</span>
<span id="900">900</span>
<span id="901">901</span>
<span id="902">902</span>
<span id="903">903</span>
<span id="904">904</span>
<span id="905">905</span>
<span id="906">906</span>
<span id="907">907</span>
<span id="908">908</span>
<span id="909">909</span>
<span id="910">910</span>
<span id="911">911</span>
<span id="912">912</span>
<span id="913">913</span>
<span id="914">914</span>
<span id="915">915</span>
</pre><pre class="rust"><code><span class="comment">// DO NOT EDIT THIS FILE. This file is automatically generated by &#39;build.rs&#39;, combining</span>
<span class="comment">// the module documentation at &#39;src/lexer_doc.md&#39; with the code from &#39;src/lib_content.rs&#39;.</span>
<span class="comment">//</span>
<span class="comment">// To edit the documentation for the top-level module of this crate, or to edit that</span>
<span class="comment">// module itself, edit the previous two documents, respectively.</span>

<span class="attribute">#![<span class="ident">allow</span>(<span class="ident">rustdoc::invalid_rust_codeblocks</span>)]</span>
<span class="doccomment">//! This crate contains facilities for generating [lexers][wl] which can parse or lex</span>
<span class="doccomment">//! input into [`Token`]&#39;s.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Creating [lexers](Lexer) can be done using either the [`LexerWriter`] struct:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! use lex::LexerWriter;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let mut buffer = Vec::new();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let rules = r#&quot;</span>
<span class="doccomment">//! id : &quot;[a-zA-Z_][0-9a-zA-Z_]*&quot;</span>
<span class="doccomment">//! ignore : &quot;[[:space:]]+&quot;</span>
<span class="doccomment">//! int : &quot;[0-9]+&quot;</span>
<span class="doccomment">//! error : &quot;/&quot;&quot;#;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let writer = LexerWriter::from_str(rules).unwrap();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! writer.write(&amp;mut buffer).unwrap();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let lexer_text = String::from_utf8(buffer).unwrap();</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! the [`write_from_str`] or [`write_from_reader`] functions:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! let mut buffer = Vec::new();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let rules = r#&quot;</span>
<span class="doccomment">//! id : &quot;[a-zA-Z_][0-9a-zA-Z_]*&quot;</span>
<span class="doccomment">//! ignore : &quot;[[:space:]]+&quot;</span>
<span class="doccomment">//! int : &quot;[0-9]+&quot;</span>
<span class="doccomment">//! error : &quot;/&quot;&quot;#;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! lex::write_from_str(rules, &amp;mut buffer).unwrap();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let lexer_text = String::from_utf8(buffer).unwrap();</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! or using the [`LexerBuilder`]struct or [`build_lexer`] function inside a [build</span>
<span class="doccomment">//! script][bs] (this is most likely what you want):</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` no_run</span>
<span class="doccomment">//! // in build.rs</span>
<span class="doccomment">//! use lex::{LexerBuilder, LexerBuilderError};</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn main() -&gt; Result &lt;(), LexerBuilderError&gt; {</span>
<span class="doccomment">//! 	let mut builder = LexerBuilder::new().unwrap();</span>
<span class="doccomment">//! 	builder</span>
<span class="doccomment">//! 		.with_name(&quot;my_lexer&quot;)?</span>
<span class="doccomment">//! 		.build()?;</span>
<span class="doccomment">//! 	Ok(())</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! All three methods ultimately use [`LexerWriter`], which is created using</span>
<span class="doccomment">//! [`from_str`](LexerWriter::from_str) to parse a source string, and which contains the</span>
<span class="doccomment">//! data necessary to write a lexer module. The other two methods are essentially just</span>
<span class="doccomment">//! convinience wrappers around [`LexerWriter::from_str`] and [`LexerWriter::write`].</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! When using the [`LexerBuilder`] struct, the resulting lexer can be included using the</span>
<span class="doccomment">//! macro [`lexer`]. For example:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! In `build.rs`</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` no_run</span>
<span class="doccomment">//! // in build.rs</span>
<span class="doccomment">//! use lex::{LexerBuilder, LexerBuilderError};</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn main() -&gt; Result &lt;(), LexerBuilderError&gt; {</span>
<span class="doccomment">//! 	let mut builder = LexerBuilder::new().unwrap();</span>
<span class="doccomment">//! 	builder</span>
<span class="doccomment">//! 		.with_name(&quot;my_lexer&quot;)?</span>
<span class="doccomment">//! 		.build()?;</span>
<span class="doccomment">//! 	Ok(())</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! In `src/lib.rs`</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` ignore</span>
<span class="doccomment">//! lex::lexer!(&quot;my_lexer&quot;);</span>
<span class="doccomment">//! use lexer::LexerRules;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! //</span>
<span class="doccomment">//! //</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let rules = LexerRules::new();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let tokens = rules::lex(src);</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # Lexers</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## About</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [Lexers][wl] (also called &quot;tokenizers&quot;,) are, generally speaking, components that can</span>
<span class="doccomment">//! scan a text and &quot;tokenize&quot; it or brake it up into &quot;tokens&quot;, which are the basic,</span>
<span class="doccomment">//! discreet units used to analyze the text. For example, in the following line of Rust</span>
<span class="doccomment">//! code:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! let x = 5 + 4;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! the tokens would be: `let`, `x`, `=`, `5`, `+`, `4`, and `;` (there are also spaces</span>
<span class="doccomment">//! inbetween these tokens, but these are [ignored][ei] by the compiler.) These tokens are</span>
<span class="doccomment">//! also categorized in a way that the compiler understand (namely `KW_LET`, `IDENTIFIER`,</span>
<span class="doccomment">//! `Eq`, `INTEGER_LITERAL`, `Plus`, `INTEGER_LITERAL`, and `Semi` respectively) and may</span>
<span class="doccomment">//! also carry around data about their location in the source for error</span>
<span class="doccomment">//! messages.[^rust_tok]</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [^rust_tok]: See the</span>
<span class="doccomment">//! [reference](https://doc.rust-lang.org/stable/reference/lexical-structure.html) for</span>
<span class="doccomment">//! more details on how Rust in particular handles tokens.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! This crate contains code for automatically generating Rust source code for lexers, as</span>
<span class="doccomment">//! well as the dependencies used by them. Once generated, these lexers can be included</span>
<span class="doccomment">//! and used in any package that has this crate as a dependency. This process can be</span>
<span class="doccomment">//! automated using [build scripts][bs] with cargo, with the helper struct</span>
<span class="doccomment">//! [`LexerBuilder`] and macro [`lexer!`].</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Lexer Structure</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! These lexers are written as module named `lexer` containing 4 public items. These are:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! * An enum called `TokenKind`, whose variants are constants of the form `&lt;name&gt;` for</span>
<span class="doccomment">//! each [token rule](crate#rules) except for [`ignore` and `error`][ei] (if present,) and</span>
<span class="doccomment">//! acts as the discriminant for [`Token`]&#39;s returned by the lexer. `TokenKind` implements</span>
<span class="doccomment">//! [`Debug`](std::fmt::Debug), [`Clone`], [`Copy`], [`PartialEq`], [`Eq`],</span>
<span class="doccomment">//! [`PartialOrd`], [`Ord`], and [`Hash`](std::hash::Hash). It also implements</span>
<span class="doccomment">//! [`Display`](std::fmt::Display), with the displayed value for a variant being</span>
<span class="doccomment">//! &quot;`&lt;name&gt;`&quot;.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! * A type alias `Token&lt;&#39;a&gt;` which is an alias for [`Token&lt;&#39;a, TokenKind&gt;`], the type of</span>
<span class="doccomment">//! tokens parsed by the lexer. [See there] for more details.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! * A struct `Lexer`, which is the type of lexers created for the modules. `Lexer`</span>
<span class="doccomment">//! implements two methods described in the trait [`Lexer`]: [`new`](Lexer::new), which</span>
<span class="doccomment">//! creates a new instance of a `Lexer`, containing all the rules and data necessary for</span>
<span class="doccomment">//! lexing an input, and [`lex`](IntoTokens::lex), which creates an instance of `Tokens`,</span>
<span class="doccomment">//! which iterates over the lazily parsed `Token`&#39;s of a given input.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! * And finaly, a struct called `Tokens&lt;&#39;r, &#39;s&gt;`, where `&#39;r` is the lifetime of the</span>
<span class="doccomment">//! `Lexer` that spawned it (see above), and `&#39;s` is the lifetime of its input text.</span>
<span class="doccomment">//! `Tokens&lt;&#39;_, &#39;s&gt;` implements the [`Tokens&lt;&#39;s, TokenKind&gt;`] trait with `TokenKind` (see</span>
<span class="doccomment">//! above) being the discriminant. This means in particular that `Tokens` is an [Iterator]</span>
<span class="doccomment">//! over the lazily parsed tokens of its input, with the [item](Iterator::Item) type being</span>
<span class="doccomment">//! [`Result&lt;Token&lt;&#39;_&gt;, Error&gt;`]; returning an [`Err`] when the [error rule][ei] is</span>
<span class="doccomment">//! triggered, or when encountering an unmatchable string, and returning [`Ok(token)`]</span>
<span class="doccomment">//! otherwise.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! The public interfaces of both `Lexer` and `Tokens` are completely described by the</span>
<span class="doccomment">//! corresponding traits [`Lexer`] and [`Tokens`], respectively. However, both types are</span>
<span class="doccomment">//! guarenteed to seperately implement all off the methods of their respective traits,</span>
<span class="doccomment">//! **with no difference between the two implementation**. In particular the type `Lexer`</span>
<span class="doccomment">//! implements `lex` as a method of type `&lt;&#39;r, &#39;s&gt;(&amp;&#39;r self, inp: &amp;&#39;s str) -&gt; Tokens&lt;&#39;r,</span>
<span class="doccomment">//! &#39;s&gt;`. This means that the interfaces for these types can be used without having to</span>
<span class="doccomment">//! import the associated traits. For example:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` ignore</span>
<span class="doccomment">//! lex::lexer!();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! use lexer::Lexer;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let first_lexer = Lexer::new();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let identical_lexer = &lt;Lexer as lex::Lexer&lt;_&gt;&gt;::new();	// same as &#39;first_lexer&#39;;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Note that the `#[allow(unused_code)]` attribute is set for the generated module, so</span>
<span class="doccomment">//! compiler warnings wont be generated for not using any of the items, just like with an</span>
<span class="doccomment">//! external crate. For example, in the above example the items `Error`, `Token`, and</span>
<span class="doccomment">//! `Tokens` are not used, but no warning would be generated.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # Lexer Definitions</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Rules</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Lexer definitions are utf-8 formatted strings (such as rust&#39;s [str] and [String]) that</span>
<span class="doccomment">//! define a list of rules for parsing tokens (see [below](crate#syntax) for the syntax.)</span>
<span class="doccomment">//! Each rule defines a *name* and a *regex*, where the *name* introduces a new category</span>
<span class="doccomment">//! of tokens to recognize, and *regex* is a non-empty-matching regex that describes how</span>
<span class="doccomment">//! to identify the category of token. For example, the following line introduced a rule</span>
<span class="doccomment">//! with name &quot;`ident`&quot; and with regex &quot;`\[a-zA-Z\]+\[_a-zA-Z0-9\]*`&quot;:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! ident : &quot;[a-zA-Z]+[_a-zA-Z0-9]*&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Again, see [below](crate#syntax) for details about the syntax. This means that when</span>
<span class="doccomment">//! the generated lexer (or, more accurately, an instance of</span>
<span class="doccomment">//! [`Tokens`](crate#lexer-structure) spawned by an instance of the generated</span>
<span class="doccomment">//! [`Lexer`](crate#lexer-structure) type) is parsing an input string, and the regex</span>
<span class="doccomment">//! &quot;`\[a-bA-B\]+\[_a-bA-B0-9\]*`&quot; matches the begining of the unparsed portion, the</span>
<span class="doccomment">//! matching text gets parsed and returned as an &quot;`ident`&quot; token (see</span>
<span class="doccomment">//! [above](crate#lexer-structure) and [`Token`].) The exceptions to this are rules with</span>
<span class="doccomment">//! the name &quot;`error`&quot; or &quot;`ignore`&quot; (see [below][ei].)</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! If no rules can be matched to the begining of the unparsed input, then the lexer</span>
<span class="doccomment">//! returns an [`Error`].</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Note that the order in which the rules are defined *does* matter: if multiple rules</span>
<span class="doccomment">//! match the begining of the unparsed portion of the input, then the first defined rule</span>
<span class="doccomment">//! matches. This may cause unexpected problems where an input is valid when parsed one</span>
<span class="doccomment">//! way, but invalid when parsed another. For example, suppose you have a lexer with two</span>
<span class="doccomment">//! rules:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! foo : &quot;abc&quot;</span>
<span class="doccomment">//! bar : &quot;abc.*def&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! And suppose you tried to lex the following input:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! abc def</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! This whole string would match &quot;`bar`&quot;, but since &quot;`foo`&quot; is defined first it instead</span>
<span class="doccomment">//! matches &quot;`abc`&quot; to `foo`, and then raises an error for &quot;` def`&quot;, since neither &quot;`foo`&quot;</span>
<span class="doccomment">//! nor &quot;`bar`&quot; matches &quot;` def`&quot;.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Rules also cannot be defined twice: that is, no two rules can have the same name.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## `error` and `ignore`</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Rules with the [name](crate#rules) &quot;`error`&quot; or &quot;`ignore`&quot; behave differently from</span>
<span class="doccomment">//! normal rules: rather than of defining a type of token and describing how to recognize</span>
<span class="doccomment">//! it, they insted trigger special behaviour by the lexer when ther</span>
<span class="doccomment">//! [regexes](crate#rules) match.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! When the `error` rule is matched, instead of returning a token, the lexer returns an</span>
<span class="doccomment">//! [`Error`] with [kind](ErrorKind) [`ErrorRule`](ErrorKind::ErrorRule) and with the</span>
<span class="doccomment">//! offending text as the [`val`](Error::val). When the `ignore` rule is matched, instead</span>
<span class="doccomment">//! of returning anything, the lexer simply skips over the matched text.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Note that, just as with normal rules, the order in which `error` and/or `ignore` are</span>
<span class="doccomment">//! defined relatve to the other rules matters for matching. For example, suppose you have</span>
<span class="doccomment">//! a lexer with the following rules:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! foo : &quot;abc&quot;</span>
<span class="doccomment">//! bar : &quot;def&quot;</span>
<span class="doccomment">//! error : &quot;abc def&quot;</span>
<span class="doccomment">//! ignore : &quot;[[:space:]]+&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! And suppose it&#39;s trying to lex the following input:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! abc def</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! This would return the tokens &quot;`foo(abc)`&quot; and &quot;`bar(def)`&quot; without error, despite the</span>
<span class="doccomment">//! fact that `error` matches the whole text, because `foo` is defined before `error`; it</span>
<span class="doccomment">//! would first match `foo` against &quot;`abc`&quot;, then `ignore` against &quot;` `&quot;, and then `bar`</span>
<span class="doccomment">//! against &quot;`def`&quot;.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Syntax</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ### Rule Syntax</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! As decribed [above](crate#rules), a lexer definition is a utf-8 string defining a list</span>
<span class="doccomment">//! of rules to use when lexing. Rules are seperated by newlines (&#39;\n&#39; `U+000A`) and empty</span>
<span class="doccomment">//! lines are ignored. The general syntax for a rule is as follows:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! rule ::= name | divider | regex			(no newlines)</span>
<span class="doccomment">//! name ::= [[:alpha:]][_0-9[:alpha:]]*	(except &#39;crate&#39;, &#39;self&#39;, &#39;super&#39;, and &#39;Self&#39;)</span>
<span class="doccomment">//! divider ::= [[:space:]]:[[:space:]]</span>
<span class="doccomment">//! regex ::= &quot;.+&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Whitespace between the components of a `rule` is generally ignored, with the exception</span>
<span class="doccomment">//! of `divider`&#39;s which, as noted above, must have at least one whitespace character</span>
<span class="doccomment">//! between it and the `name` and `regex`, and with the exception that newlines (`U+000A`)</span>
<span class="doccomment">//! cannot occur within a rule.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! A `rule` consists of a [`name`](crate#rules), a `divider` (&#39;`:`&#39;), and a</span>
<span class="doccomment">//! [`regex`](crate#rules). A `name` must start with an ASCII alphabetical character</span>
<span class="doccomment">//! (`[a-zA-Z]`) followed by any sequence of ASCII alphabetical characters, underscores</span>
<span class="doccomment">//! (&#39;`_`&#39;), or digits (`[0-9]`). For example</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! Foo : &quot;\W(Foo)+\W&quot;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! f_0O : &quot;(?P&lt;interpunct&gt;\u00B7)(?P&lt;word&gt;\w+)&quot;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! trailing_whitespace : &quot;((?m)\s+$)&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! The only exceptions to this are the terms &quot;`crate`&quot;, &quot;`self`&quot;, &quot;`super`&quot;, and</span>
<span class="doccomment">//! &quot;`Self`&quot;, which cannot be used as `name`&#39;s. This is due to restrictions rust places on</span>
<span class="doccomment">//! its own identifiers and how the generated [lexers](crate#lexer-structure) are</span>
<span class="doccomment">//! implemented.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! A `divider` is the character &#39;`:`&#39; (`U+003A`) with at least one (non-newline)</span>
<span class="doccomment">//! whitespace character between it and the `name`, and between it and the `regex`</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! A `regex` is a [regular expression](https://en.wikipedia.org/wiki/Regular_expression)</span>
<span class="doccomment">//! introduced by a &#39;`&quot;`&#39; (`U+0022`) and ended by another &#39;`&quot;`&#39;. `&quot;`&#39;s within a `regex` do</span>
<span class="doccomment">//! not need to be escaped (and in fact, trying to escape them will raise an</span>
<span class="doccomment">//! [error](::regex::Error) as a non-recognized escape sequence,) but no non-whitespace</span>
<span class="doccomment">//! characters can occur after the final &#39;`&quot;`&#39;. For example, in the following definition:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! quote : &quot;(&quot;\w*&quot;)|(&#39;\w*&#39;)&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! the rule `quote` matches any word surrounded by &#39;`&quot;`&#39;, or by &#39;`&#39;`&#39;, with the two `&quot;`&#39;s</span>
<span class="doccomment">//! appearing between the initial &#39;`&quot;`&#39; and the final &#39;`&quot;`&#39; being interpreted as literal</span>
<span class="doccomment">//! &#39;`&quot;`&#39;&#39;s.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! `regex`&#39;s are parsed according to the crate [`regex`](::regex) (with one</span>
<span class="doccomment">//! exception[^exception],) using the same default flags, and must be valid regular</span>
<span class="doccomment">//! expressions according to the [rules of that crate](::regex#syntax). For example, the</span>
<span class="doccomment">//! rule:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! space_no_nl : &quot;[[:space:]&amp;&amp;[^\n]]&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! would be valid and would match any sing ASCII whitespace character except for &#39;`\n`&#39;,</span>
<span class="doccomment">//! while the rule:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text compile_fail</span>
<span class="doccomment">//! start_with_a_invalid : &quot;a(*)&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! would be invalid since the repition operator `*` is unescaped and lacks an expression</span>
<span class="doccomment">//! to operate on.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! See the [documentation on the crate `regex`](::regex#syntax) for more info.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [^exception]: The one exception is that an anchor &#39;`^`&#39; always matches the begining of</span>
<span class="doccomment">//! the unparsed input (as well as the beginings of lines if [the `m` flag is</span>
<span class="doccomment">//! set](#grouping-and-flags).) For example the regex &quot;`^abc`&quot; would behave almost exactly</span>
<span class="doccomment">//! like the regex &quot;`abc`&quot;, the one exception to *that* being error messages, where, upon</span>
<span class="doccomment">//! encountering a section of text that cannot be matched, the lexer will search ahead to</span>
<span class="doccomment">//! find the nearest matching text in order to define the range of text that cannot be</span>
<span class="doccomment">//! matched. When this happens, anchors in regexes currently still match against the</span>
<span class="doccomment">//! begining the remaining text, including the unmachable portion. So, for example, if you</span>
<span class="doccomment">//! were to have two lexers, each with a single rule, with regexes &quot;`^abc`&quot; and &quot;`abc`&quot;</span>
<span class="doccomment">//! respectively, both would behave the same on the input &quot;`abcabc`&quot;, returning two tokens</span>
<span class="doccomment">//! with the content &quot;`abc`&quot;. But, on the string &quot;`abcdefabc`&quot;, while both lexers would</span>
<span class="doccomment">//! retrun a token with &quot;`abc`&quot;, and both lexers would then return an error, in that error</span>
<span class="doccomment">//! the second lexer would report the string &quot;`def`&quot; (up to the begining of &quot;`abc`&quot; in</span>
<span class="doccomment">//! &quot;`defabc`&quot;) as being unparsable, while the first would report the string &quot;`defabc`&quot; as</span>
<span class="doccomment">//! being unparsable (since &quot;`^abc`&quot; doesn&#39;t match anywhere in &quot;`defabc`&quot;,) returning a</span>
<span class="doccomment">//! less precise error message. This might be fixed later.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! #### Escapes</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Note that, because the utf-8 text is used directly to create a</span>
<span class="doccomment">//! [`Regex`](crate::Regex), when writing a `.lex` source file with a text editor the</span>
<span class="doccomment">//! result is equivalent to calling [`Regex::new`] on the `regex` interpreted as a rust</span>
<span class="doccomment">//! [raw string</span>
<span class="doccomment">//! literal](https://doc.rust-lang.org/reference/tokens.html#raw-string-literals) (with an</span>
<span class="doccomment">//! `r` before the string, followed by as many `#`&#39; as necessary.) For example, the rule:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! name : &quot;\w+&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! matches any non-empty sequence of unicode word characters, but if you were to try the</span>
<span class="doccomment">//! following in rust:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` compile_fail</span>
<span class="doccomment">//! # //use lex::regex;</span>
<span class="doccomment">//! use regex::Regex;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn main() {</span>
<span class="doccomment">//! 	let name = Regex::new(&quot;\w+&quot;).unwrap();</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! you would get the following error:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! error: unknown character escape: `w`</span>
<span class="doccomment">//!  --&gt; src/main.rs:4:26</span>
<span class="doccomment">//!   |</span>
<span class="doccomment">//! 4 |     let name = Regex::new(&quot;\w+&quot;).unwrap();</span>
<span class="doccomment">//!   |                             ^ unknown character escape</span>
<span class="doccomment">//!   |</span>
<span class="doccomment">//!   = help: for more information, visit &lt;https://static.rust-lang.org/doc/master/reference.html#literals&gt;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! because the sequence &quot;`\w`&quot; would be parsed as an escape sequence at the level of the</span>
<span class="doccomment">//! rust source code, which would trigger an error since &quot;`\w`&quot; is not a valid [escape</span>
<span class="doccomment">//! sequence](https://doc.rust-lang.org/reference/tokens.html#character-escapes) in rust.</span>
<span class="doccomment">//! However, if we were to instead use one of the following examples:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! # //use lex::regex;</span>
<span class="doccomment">//! use regex::Regex;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let name = Regex::new(r&quot;\w+&quot;).unwrap();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let equivalent_name = Regex::new(&quot;\\w+&quot;).unwrap();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! assert_eq!(name.as_str(), equivalent_name.as_str());</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! it would work fine, since, with either option, a string consisting of the characters</span>
<span class="doccomment">//! &#39;`\`&#39;, &#39;`w`&#39;, and &#39;`+`&#39; would be sent to [`Regex::new`](::regex::Regex::new), and so</span>
<span class="doccomment">//! the sequence &quot;`\w`&quot; would get processed on the level of the regex (specifically [as a</span>
<span class="doccomment">//! character class matching unicode word</span>
<span class="doccomment">//! characters](::regex#perl-character-classes-unicode-friendly).) However, if were to use</span>
<span class="doccomment">//! the second option, &quot;`\\w+`&quot;, for our rule instead:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! incorect_word : &quot;\\w+&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! This would be the equivalent of:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! # //use lex::regex;</span>
<span class="doccomment">//! use regex::Regex;</span>
<span class="doccomment">//! Regex::new(r&quot;\\w+&quot;).unwrap();</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! which would match a literal &#39;`\`&#39;, followed by a non-empty sequence of `w`&#39;s!</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ### Coments</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Comments can also be used with lexer definitions: A line that has `#` (`U+0023`) as</span>
<span class="doccomment">//! its first non-space character is interpreted as a comment and is ignored. For example:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! ## this is a lexer definition file</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## this rule is for identifiers</span>
<span class="doccomment">//! id : &quot;[[:alpha:]][_0-9[:alpha:]]*&quot;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## this is for integer literals</span>
<span class="doccomment">//! int : &quot;[0-9]+&quot;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## multiplication and addition</span>
<span class="doccomment">//! mult : &quot;\*&quot;</span>
<span class="doccomment">//! plus : &quot;\+&quot;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## this line is a comment explaning that the following line is a rule for identifying comments</span>
<span class="doccomment">//! comment : &quot;[[:space:]]*#.*$&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # Example</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Suppose you want to build a simple calculator that can handle addition and subtraction</span>
<span class="doccomment">//! on integers, as well as understand decimal, hexadecimal, octal, and binary integers in</span>
<span class="doccomment">//! the same format as [rust integer literals][il] (without underscores, for simplicity.)</span>
<span class="doccomment">//! We would start by making a new project &quot;`calculator`&quot; with `cargo new`, which would</span>
<span class="doccomment">//! give us something like the following directory structure:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! calculator/</span>
<span class="doccomment">//! ├── Cargo.toml</span>
<span class="doccomment">//! └── src/</span>
<span class="doccomment">//!     └── main.rs</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Next, edit `Cargo.toml` to add this crate as a dependency *and* a build dependency. It</span>
<span class="doccomment">//! should look something like this:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! [package]</span>
<span class="doccomment">//! name = &quot;calculator&quot;</span>
<span class="doccomment">//! version = &quot;0.1.0&quot;</span>
<span class="doccomment">//! edition = &quot;2021&quot;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [dependencies]</span>
<span class="doccomment">//! lex = { version = &quot;0.1.0&quot;, git = &quot;https://github.com/dsmcdermott/rly&quot; }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [build-dependencies]</span>
<span class="doccomment">//! lex = { version = &quot;0.1.0&quot;, git = &quot;https://github.com/dsmcdermott/rly&quot; }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ([`lex`](self) needs to be added as a build dependency so that we can use it in</span>
<span class="doccomment">//! `build.rs`.)</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Then, make a file called &quot;[`build.rs`][bs]&quot; in the package root directory with the</span>
<span class="doccomment">//! following contents:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` no_run</span>
<span class="doccomment">//! // build.rs</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! use lex::{LexerBuilder, LexerBuilderError};</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn main() -&gt; Result&lt;(), LexerBuilderError&gt; {</span>
<span class="doccomment">//! 	LexerBuilder::new()</span>
<span class="doccomment">//! 		.unwrap()</span>
<span class="doccomment">//! 		.build()?</span>
<span class="doccomment">//! 		.set_rerun()</span>
<span class="doccomment">//! 		.unwrap();</span>
<span class="doccomment">//! 	Ok(())</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! What this does is create a new [`LexerBuilder`], call [`build`](LexerBuilder::build)</span>
<span class="doccomment">//! to build a lexer, and then call [`set_rerun`](LexerBuilder::set_rerun) to set cargo to</span>
<span class="doccomment">//! watch our lexer source file for changes and rerun the build script when it detects</span>
<span class="doccomment">//! one.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Now, if you were to try to build the package as-is, with `cargo build`, you would</span>
<span class="doccomment">//! encounter the following error:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//!    Compiling calculator v0.1.0 (/path/to/project/calculator)</span>
<span class="doccomment">//! error: failed to run custom build command for `calculator v0.1.0 (/path/to/project/calculator)`</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Caused by:</span>
<span class="doccomment">//!   process didn&#39;t exit successfully: `/path/to/project/calculator/target/debug/build/calculator-&lt;hash&gt;/build-script-build` (exit status: 1)</span>
<span class="doccomment">//!   --- stderr</span>
<span class="doccomment">//!   Error: IO(Os { code: 2, kind: NotFound, message: &quot;No such file or directory&quot; })</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! This is because [`LexerBuilder`] cannot find our lexer source file (because we haven&#39;t</span>
<span class="doccomment">//! written any yet.) As explained at [`LexerBuilder`](LexerBuilder#name-and-location),</span>
<span class="doccomment">//! the [`LexerBuilder`], by default, looks for a source file with the name of the current</span>
<span class="doccomment">//! project plus &quot;`_lex.lex`&quot;.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! So, our next step is to make this file. Remember, we want to be able to recognize</span>
<span class="doccomment">//! addition and subtraction (as well as negation,) and be able to recognize numbers</span>
<span class="doccomment">//! written in base 2, 8, 10, and 16 using [the same format as rust][il]. Let&#39;s also say</span>
<span class="doccomment">//! that whitespace is ignored.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! (Before reading further, it might be worthwhile to try and come up with a `.lex` file</span>
<span class="doccomment">//! yourself as an exercise. Using [the &#39;syntax&#39; section of this</span>
<span class="doccomment">//! documentation](self#syntax) and [the rust integer literal rules][il] (remember, we&#39;re</span>
<span class="doccomment">//! ignoring underscores &#39;`_`&#39; between digits for simplicity&#39;s sake) as guides, try and</span>
<span class="doccomment">//! make a valid `.lex` file that achieves what we want, and compare your answer to the</span>
<span class="doccomment">//! sample given below.)</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! We would therefore make a file called `calculator_lex.lex` as follows[^precedence]:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! ## calculator_lex.lex</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! BIN : &quot;0b[01]+&quot;</span>
<span class="doccomment">//! OCT : &quot;0o[0-7]+&quot;</span>
<span class="doccomment">//! HEX : &quot;0x[0-9a-fA-F]+&quot;</span>
<span class="doccomment">//! DEC : &quot;[0-9]+&quot;</span>
<span class="doccomment">//! PLUS : &quot;\+&quot;</span>
<span class="doccomment">//! MINUS : &quot;-&quot;</span>
<span class="doccomment">//! ignore : &quot;\s+&quot;</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [^precedence]: Note that because of the [precedence rules](self#rules) the order in</span>
<span class="doccomment">//! which `DEC` is placed relative to `BIN`, `OCT`, and `HEX` does matter! For example, if</span>
<span class="doccomment">//! `DEC` were placed higher than `HEX`, then when trying to lex &quot;`0xA`&quot; it would first</span>
<span class="doccomment">//! return &quot;`0`&quot; as a `DEC`, and then return an [`Error`] for &quot;`xA`&quot;, instead of just</span>
<span class="doccomment">//! parsing the whole thing as a `HEX`, which is clearly not what we want.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Your directory structure should look something like this (minus any `Cargo.lock` or</span>
<span class="doccomment">//! `target/` files:)</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` text</span>
<span class="doccomment">//! calculator/</span>
<span class="doccomment">//! ├── build.rs</span>
<span class="doccomment">//! ├── calculator_lex.lex</span>
<span class="doccomment">//! ├── Cargo.toml</span>
<span class="doccomment">//! └── src/</span>
<span class="doccomment">//!     └── main.rs</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! The next step, after having made a build script to automatically generate our lexer,</span>
<span class="doccomment">//! is to include that lexer in our source code. [`LexerBuilder`] writes the</span>
<span class="doccomment">//! [module](self#lexer-structure) it generates to the directory set by cargo in the</span>
<span class="doccomment">//! [`OUT_DIR`][od] environment variable, and it by default writes it as a file with the</span>
<span class="doccomment">//! name of the package plus &quot;`_lex.rs`&quot;. Therefore, if wanted to include the lexer in our</span>
<span class="doccomment">//! code, we could do something like this:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` ignore</span>
<span class="doccomment">//! include!(concat!(env!(&quot;OUT_DIR&quot;), &quot;/calculator_lex.rs&quot;));</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! However, this crate already contains a helper macro [`lexer!`] which we can use</span>
<span class="doccomment">//! instead:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` ignore</span>
<span class="doccomment">//! // src/main.rs</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! lex::lexer!();</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Either way, this includes a [module](self#lexer-structure) called &quot;`lexer`&quot;, generated</span>
<span class="doccomment">//! by [`LexerBuilder`] which contains the type `Lexer` whose instances can lex inputs by</span>
<span class="doccomment">//! spawning `Tokens`&#39;, which iterate over the lazily parsed tokens of a given input (see</span>
<span class="doccomment">//! [above](self#lexer-structure) for more details.)</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Now that we have our lexer, we can use it to write our calculator. Write the following</span>
<span class="doccomment">//! for `src/main.rs`:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ``` ignore</span>
<span class="doccomment">//! // src/main.rs</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! use std::io;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! lex::lexer!();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! use lexer::{Lexer, Token, TokenKind, Tokens};</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! // Our error type.</span>
<span class="doccomment">//! #[derive(Debug)]</span>
<span class="doccomment">//! enum Error {</span>
<span class="doccomment">//!     MissingOperand,</span>
<span class="doccomment">//!     UnexpectedInt,</span>
<span class="doccomment">//!     LexerError(lex::Error),</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! use Error::*;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! impl From&lt;lex::Error&gt; for Error {</span>
<span class="doccomment">//!     fn from(err: lex::Error) -&gt; Self {</span>
<span class="doccomment">//!         LexerError(err)</span>
<span class="doccomment">//!     }</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! type Result&lt;T&gt; = std::result::Result&lt;T, Error&gt;;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn main() {</span>
<span class="doccomment">//!     let mut buffer = String::new();</span>
<span class="doccomment">//!     let stdin = io::stdin();</span>
<span class="doccomment">//!     loop {</span>
<span class="doccomment">//!         buffer.clear();</span>
<span class="doccomment">//!         stdin.read_line(&amp;mut buffer).expect(&quot;unable to read input&quot;);</span>
<span class="doccomment">//!         println!(&quot;{}&quot;, parse(&amp;buffer).expect(&quot;unable to parse input&quot;));</span>
<span class="doccomment">//!     }</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn parse_dec(tok: Token&lt;&#39;_&gt;) -&gt; i32 {</span>
<span class="doccomment">//!     tok.val().parse::&lt;i32&gt;().unwrap()</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn parse_bin(tok: Token&lt;&#39;_&gt;) -&gt; i32 {</span>
<span class="doccomment">//!     i32::from_str_radix(&amp;tok.val()[2..], 2).unwrap()</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn parse_oct(tok: Token&lt;&#39;_&gt;) -&gt; i32 {</span>
<span class="doccomment">//!     i32::from_str_radix(&amp;tok.val()[2..], 8).unwrap()</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn parse_hex(tok: Token&lt;&#39;_&gt;) -&gt; i32 {</span>
<span class="doccomment">//!     i32::from_str_radix(&amp;tok.val()[2..], 16).unwrap()</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! // Parses an integer when expecting one as an operand to &quot;op&quot;. Like parse_integer except</span>
<span class="doccomment">//! // returns an err if no tokens remain in &#39;tokens&#39;.</span>
<span class="doccomment">//! fn parse_operand(tokens: &amp;mut Tokens&lt;&#39;_, &#39;_&gt;) -&gt; Result&lt;i32&gt; {</span>
<span class="doccomment">//!     parse_integer(tokens)?.ok_or(MissingOperand)</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! // Attempts to parse an integer from &#39;tokens&#39;, returnin Ok(None) if no tokens remain.</span>
<span class="doccomment">//! fn parse_integer(tokens: &amp;mut Tokens&lt;&#39;_, &#39;_&gt;) -&gt; Result&lt;Option&lt;i32&gt;&gt; {</span>
<span class="doccomment">//!     let tok = match tokens.next() {</span>
<span class="doccomment">//!         Some(result) =&gt; result?,</span>
<span class="doccomment">//!         None =&gt; return Ok(None),</span>
<span class="doccomment">//!     };</span>
<span class="doccomment">//!     // Match the token kind to determine how to proceed.</span>
<span class="doccomment">//!     Ok(Some(match tok.kind() {</span>
<span class="doccomment">//!         TokenKind::DEC =&gt; parse_dec(tok),</span>
<span class="doccomment">//!         TokenKind::BIN =&gt; parse_bin(tok),</span>
<span class="doccomment">//!         TokenKind::OCT =&gt; parse_oct(tok),</span>
<span class="doccomment">//!         TokenKind::HEX =&gt; parse_hex(tok),</span>
<span class="doccomment">//!         // If the current token is a unary &quot;+&quot; operator, just return the next parsed</span>
<span class="doccomment">//!         // integer. (&quot;+3&quot; is the same as &quot;3&quot;)</span>
<span class="doccomment">//!         TokenKind::PLUS =&gt; parse_operand(tokens)?,</span>
<span class="doccomment">//!         // If the current token is a unary &quot;-&quot; operator, return the negative version of</span>
<span class="doccomment">//!         // the next integer.</span>
<span class="doccomment">//!         TokenKind::MINUS =&gt; -parse_operand(tokens)?,</span>
<span class="doccomment">//!     }))</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! // Parse a string by calculating its value.</span>
<span class="doccomment">//! fn parse&lt;S: AsRef&lt;str&gt;&gt;(inp: S) -&gt; Result&lt;i32&gt; {</span>
<span class="doccomment">//!     // our lexer</span>
<span class="doccomment">//!     let lexer = Lexer::new();</span>
<span class="doccomment">//!     // our &#39;Tokens&#39; instance. Iterates over the lazily parsed tokens of &#39;inp&#39;</span>
<span class="doccomment">//!     let mut tokens = lexer.lex(inp.as_ref());</span>
<span class="doccomment">//!     // our accumulator, initialized to the first integer</span>
<span class="doccomment">//!     let mut acc = match parse_integer(&amp;mut tokens)? {</span>
<span class="doccomment">//!         Some(n) =&gt; n,</span>
<span class="doccomment">//!         // if the input is empty return the additive identity</span>
<span class="doccomment">//!         None =&gt; return Ok(0),</span>
<span class="doccomment">//!     };</span>
<span class="doccomment">//!     // add or subtract from the accumulator for the remaining values</span>
<span class="doccomment">//!     loop {</span>
<span class="doccomment">//!         // break if no more tokens remaining</span>
<span class="doccomment">//!         let tok = match tokens.next() {</span>
<span class="doccomment">//!             Some(res) =&gt; res?,</span>
<span class="doccomment">//!             None =&gt; break,</span>
<span class="doccomment">//!         };</span>
<span class="doccomment">//!         // if the current token is &quot;+&quot;, add the next integer, if it&#39;s &quot;-&quot; subtract the</span>
<span class="doccomment">//!         // next one instead, if it&#39;s and intiger return an error</span>
<span class="doccomment">//!         match tok.kind() {</span>
<span class="doccomment">//!             TokenKind::PLUS =&gt; acc += parse_operand(&amp;mut tokens)?,</span>
<span class="doccomment">//!             TokenKind::MINUS =&gt; acc -= parse_operand(&amp;mut tokens)?,</span>
<span class="doccomment">//!             _ =&gt; return Err(UnexpectedInt),</span>
<span class="doccomment">//!         };</span>
<span class="doccomment">//!     }</span>
<span class="doccomment">//!     Ok(acc)</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Then test it out by using `cargo run`.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [od]: https://doc.rust-lang.org/stable/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-build-scripts</span>
<span class="doccomment">//! [il]: https://doc.rust-lang.org/reference/tokens.html#number-literals</span>
<span class="doccomment">//! [wl]: https://en.wikipedia.org/wiki/Lexer</span>
<span class="doccomment">//! [bs]: https://doc.rust-lang.org/cargo/reference/build-scripts.html</span>
<span class="doccomment">//! [drv]: https://doc.rust-lang.org/reference/attributes/derive.html</span>
<span class="doccomment">//! [ei]: crate#error-and-ignore</span>
<span class="doccomment">//!</span>

<span class="kw">use</span> <span class="ident">std::collections::HashSet</span>;

<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">regex</span> {
	<span class="doccomment">//! Re-exports from the [`regex`] crate used by the generated lexers. See the documentation there for more info.</span>
	<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">::regex</span>::{<span class="ident">Match</span>, <span class="ident">Regex</span>, <span class="ident">RegexSet</span>};
}
<span class="kw">use</span> <span class="ident"><span class="kw">crate</span>::regex</span>::{<span class="ident">Regex</span>, <span class="ident">RegexSet</span>};

<span class="kw">mod</span> <span class="ident">lexer_writer</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">lexer_writer</span>::{<span class="ident">write_from_reader</span>, <span class="ident">write_from_str</span>, <span class="ident">LexerWriter</span>};

<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">rly_common</span> {
	<span class="doccomment">//! Re-exports from the [`rly_common`] crate used by the generated lexers. See the documentation there for more info.</span>
	<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">rly_common::errors::ErrorData</span>;
}

<span class="kw">mod</span> <span class="ident">error</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">error</span>::{<span class="ident">FmtError</span>, <span class="ident">LexerBuilderError</span>, <span class="ident">LexerError</span>, <span class="ident">LexerErrorKind</span>};

<span class="kw">mod</span> <span class="ident">lexers</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">lexers</span>::{<span class="ident">Error</span>, <span class="ident">ErrorKind</span>, <span class="ident">IntoTokens</span>, <span class="ident">Lexer</span>, <span class="ident">Tokens</span>};

<span class="kw">mod</span> <span class="ident">token</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">token::Token</span>;

<span class="attribute">#[<span class="ident">derive</span>(<span class="ident">Debug</span>, <span class="ident">Clone</span>, <span class="ident">Copy</span>)]</span>
<span class="comment">// Represents a rule for lexing tokens.</span>
<span class="comment">// The first element is the name and the second is the regex-string for the rule.</span>
<span class="kw">struct</span> <span class="ident">TokenRule</span><span class="op">&lt;</span><span class="lifetime">&#39;a</span><span class="op">&gt;</span>(<span class="kw-2">&amp;</span><span class="lifetime">&#39;a</span> <span class="ident">str</span>, <span class="kw-2">&amp;</span><span class="lifetime">&#39;a</span> <span class="ident">str</span>);

<span class="kw">impl</span><span class="op">&lt;</span><span class="lifetime">&#39;a</span><span class="op">&gt;</span> <span class="ident">TokenRule</span><span class="op">&lt;</span><span class="lifetime">&#39;a</span><span class="op">&gt;</span> {
	<span class="kw">fn</span> <span class="ident">name</span>(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="kw-2">&amp;</span><span class="lifetime">&#39;a</span> <span class="ident">str</span> {
		<span class="self">self</span>.<span class="number">0</span>
	}
}

<span class="comment">// Scans src and returns a vector of TokenRules if syntactically correct.</span>
<span class="kw">fn</span> <span class="ident">scan</span>(<span class="ident">src</span>: <span class="kw-2">&amp;</span><span class="ident">str</span>) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">TokenRule</span><span class="op">&gt;</span>, <span class="ident">LexerError</span><span class="op">&gt;</span> {
	<span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">rules</span>: <span class="ident">Vec</span><span class="op">&lt;</span>(<span class="kw-2">&amp;</span><span class="ident">str</span>, (<span class="kw-2">&amp;</span><span class="ident">str</span>, <span class="ident">usize</span>))<span class="op">&gt;</span> <span class="op">=</span> <span class="ident">Vec::new</span>();
	<span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">names</span> <span class="op">=</span> <span class="ident">HashSet::new</span>();
	<span class="kw">let</span> <span class="ident">ignore</span> <span class="op">=</span> <span class="ident">RegexSet::new</span>([<span class="string">&quot;^[[:space:]]*#.*&quot;</span>, <span class="string">&quot;^[[:space:]]*$&quot;</span>]).<span class="ident">unwrap</span>();
	<span class="kw">let</span> <span class="ident">name</span> <span class="op">=</span> <span class="ident">Regex::new</span>(<span class="string">&quot;^[[:space:]]*([[:alpha:]][0-9_[:alpha:]]*)&quot;</span>).<span class="ident">unwrap</span>();
	<span class="kw">let</span> <span class="ident">div</span> <span class="op">=</span> <span class="ident">Regex::new</span>(<span class="string">&quot;^[[:space:]]+:[[:space:]]+&quot;</span>).<span class="ident">unwrap</span>();
	<span class="kw">let</span> <span class="ident">regx</span> <span class="op">=</span> <span class="ident">Regex::new</span>(<span class="string">&quot;^\&quot;(.*)\&quot;[[:space:]]*$&quot;</span>).<span class="ident">unwrap</span>();
	<span class="kw">let</span> <span class="ident">reserved</span> <span class="op">=</span> <span class="ident">Regex::new</span>(<span class="string">&quot;^(crate)|(self)|(super)|(Self)$&quot;</span>).<span class="ident">unwrap</span>();
	<span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">lines</span> <span class="op">=</span> <span class="ident">Vec::new</span>();
	<span class="kw">for</span> (<span class="ident">n</span>, <span class="ident">s</span>) <span class="kw">in</span> <span class="ident">src</span>.<span class="ident">lines</span>().<span class="ident">enumerate</span>() {
		<span class="kw">if</span> <span class="ident">ignore</span>.<span class="ident">is_match</span>(<span class="ident">s</span>) {
			<span class="kw">continue</span>;
		};
		<span class="comment">// TODO: make better error messages</span>
		<span class="kw">let</span> <span class="ident">err</span> <span class="op">=</span> <span class="op">|</span><span class="ident">val</span><span class="op">|</span> <span class="ident">LexerError::fmt</span>::<span class="op">&lt;</span><span class="kw-2">&amp;</span><span class="ident">str</span>, <span class="kw-2">&amp;</span><span class="ident">str</span><span class="op">&gt;</span>(<span class="ident">val</span>, <span class="ident">n</span>, <span class="ident">s</span>);
		<span class="kw">let</span> <span class="ident">name_match</span> <span class="op">=</span> <span class="ident">name</span>
			.<span class="ident">captures</span>(<span class="ident">s</span>)
			.<span class="ident">ok_or_else</span>(<span class="op">|</span><span class="op">|</span> <span class="ident">err</span>(<span class="string">&quot;missing or improperly formatted name for token rule&quot;</span>))<span class="question-mark">?</span>;
		<span class="kw">let</span> <span class="ident">rule_name</span> <span class="op">=</span> <span class="ident">name_match</span>.<span class="ident">get</span>(<span class="number">1</span>).<span class="ident">unwrap</span>().<span class="ident">as_str</span>();
		<span class="kw">if</span> <span class="ident">reserved</span>.<span class="ident">is_match</span>(<span class="ident">rule_name</span>) {
			<span class="kw">return</span> <span class="prelude-val">Err</span>(<span class="ident">err</span>(<span class="string">&quot;invalid name used&quot;</span>));
		};
		<span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">rest_of_line</span> <span class="op">=</span> <span class="kw-2">&amp;</span><span class="ident">s</span>[<span class="ident">name_match</span>.<span class="ident">get</span>(<span class="number">0</span>).<span class="ident">unwrap</span>().<span class="ident">end</span>()..];
		<span class="ident">rest_of_line</span> <span class="op">=</span> <span class="kw-2">&amp;</span><span class="ident">rest_of_line</span>[<span class="ident">div</span>
			.<span class="ident">find</span>(<span class="ident">rest_of_line</span>)
			.<span class="ident">ok_or_else</span>(<span class="op">|</span><span class="op">|</span> <span class="ident">err</span>(<span class="string">&quot;missing divider \&quot;:\&quot; between name and regex&quot;</span>))<span class="question-mark">?</span>
			.<span class="ident">end</span>()..];
		<span class="kw">let</span> <span class="ident">regx_val</span> <span class="op">=</span> <span class="ident">regx</span>
			.<span class="ident">captures</span>(<span class="ident">rest_of_line</span>)
			.<span class="ident">ok_or_else</span>(<span class="op">|</span><span class="op">|</span> <span class="ident">err</span>(<span class="string">&quot;missing or improperly delimited regex&quot;</span>))<span class="question-mark">?</span>
			.<span class="ident">get</span>(<span class="number">1</span>)
			.<span class="ident">unwrap</span>()
			.<span class="ident">as_str</span>();
		<span class="kw">match</span> <span class="ident">Regex::new</span>(<span class="ident">regx_val</span>) {
			<span class="prelude-val">Ok</span>(<span class="ident">comp_regx</span>) =&gt; {
				<span class="kw">if</span> <span class="ident">comp_regx</span>.<span class="ident">is_match</span>(<span class="string">&quot;&quot;</span>) {
					<span class="kw">return</span> <span class="prelude-val">Err</span>(<span class="ident">LexerError::empty</span>(<span class="ident">rule_name</span>, <span class="ident">regx_val</span>, <span class="ident">n</span>, <span class="ident">s</span>));
				}
			}
			<span class="prelude-val">Err</span>(<span class="ident">e</span>) =&gt; {
				<span class="kw">return</span> <span class="prelude-val">Err</span>(<span class="ident">LexerError::regex</span>(<span class="ident">e</span>, <span class="ident">n</span>, <span class="ident">s</span>));
			}
		};
		<span class="kw">if</span> <span class="op">!</span><span class="ident">names</span>.<span class="ident">insert</span>(<span class="ident">rule_name</span>) {
			<span class="kw">let</span> <span class="ident">prev</span> <span class="op">=</span> <span class="ident">rules</span>.<span class="ident">iter</span>().<span class="ident">find</span>(<span class="op">|</span><span class="ident">x</span><span class="op">|</span> <span class="ident">x</span>.<span class="number">0</span> <span class="op">==</span> <span class="ident">rule_name</span>).<span class="ident">unwrap</span>().<span class="number">1</span> .<span class="number">1</span>;
			<span class="kw">return</span> <span class="prelude-val">Err</span>(<span class="ident">LexerError::duplicate_name</span>(
				<span class="ident">rule_name</span>,
				<span class="ident">prev</span>,
				<span class="ident">lines</span>[<span class="ident">prev</span>],
				<span class="ident">n</span>,
				<span class="ident">s</span>,
			));
		};
		<span class="ident">rules</span>.<span class="ident">push</span>((<span class="ident">rule_name</span>, (<span class="ident">regx_val</span>, <span class="ident">n</span>)));
		<span class="ident">lines</span>.<span class="ident">push</span>(<span class="ident">s</span>);
	}
	<span class="prelude-val">Ok</span>(<span class="ident">rules</span>
		.<span class="ident">iter</span>()
		.<span class="ident">map</span>(<span class="op">|</span>(<span class="ident">name</span>, (<span class="ident">val</span>, <span class="ident">_n</span>))<span class="op">|</span> <span class="ident">TokenRule</span>(<span class="ident">name</span>, <span class="ident">val</span>))
		.<span class="ident">collect</span>())
}

<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">test</span>)]</span>
<span class="kw">mod</span> <span class="ident">tests</span> {
	<span class="kw">use</span> <span class="kw">super</span>::<span class="kw-2">*</span>;

	<span class="kw">fn</span> <span class="ident">print_err</span><span class="op">&lt;</span><span class="ident">T</span>, <span class="ident">E</span>: <span class="ident">std::fmt::Display</span><span class="op">&gt;</span>(<span class="ident">r</span>: <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">T</span>, <span class="ident">E</span><span class="op">&gt;</span>) -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">T</span>, <span class="ident">E</span><span class="op">&gt;</span> {
		<span class="ident">r</span>.<span class="ident">map_err</span>(<span class="op">|</span><span class="ident">e</span><span class="op">|</span> {
			<span class="macro">eprintln!</span>(<span class="string">&quot;{}&quot;</span>, <span class="kw-2">&amp;</span><span class="ident">e</span>);
			<span class="ident">e</span>
		})
	}

	<span class="kw">const</span> <span class="ident">TEST_DOC</span>: <span class="kw-2">&amp;</span><span class="ident">str</span> <span class="op">=</span> <span class="string">r##&quot;
name : &quot;[a-zA-Z_][0-9a-zA-Z_]*&quot;
	# test comment : &quot;&quot;  
 	 str : &quot;&quot;[^&quot;]*&quot;&quot;	


comment : &quot;#.*&quot;
&quot;##</span>;

	<span class="attribute">#[<span class="ident">test</span>]</span>
	<span class="kw">fn</span> <span class="ident">test_scan</span>() -&gt; <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">LexerBuilderError</span><span class="op">&gt;</span> {
		<span class="kw">let</span> <span class="ident">rules</span> <span class="op">=</span> <span class="ident">scan</span>(<span class="ident">TEST_DOC</span>)<span class="question-mark">?</span>;
		<span class="macro">println!</span>(<span class="string">&quot;{:?}&quot;</span>, <span class="kw-2">&amp;</span><span class="ident">rules</span>);
		<span class="macro">assert!</span>(<span class="ident">rules</span>.<span class="ident">iter</span>().<span class="ident">map</span>(<span class="op">|</span><span class="ident">x</span><span class="op">|</span> (<span class="ident">x</span>.<span class="number">0</span>, <span class="ident">x</span>.<span class="number">1</span>)).<span class="ident">eq</span>([
			(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;[a-zA-Z_][0-9a-zA-Z_]*&quot;</span>),
			(<span class="string">&quot;str&quot;</span>, <span class="string">&quot;\&quot;[^\&quot;]*\&quot;&quot;</span>),
			(<span class="string">&quot;comment&quot;</span>, <span class="string">&quot;#.*&quot;</span>)
		]));
		<span class="prelude-val">Ok</span>(())
	}

	<span class="kw">const</span> <span class="ident">TEST_DOC_FAIL_REGFMT</span>: <span class="kw-2">&amp;</span><span class="ident">str</span> <span class="op">=</span> <span class="string">r##&quot;
name : &quot;[a-zA-Z_][0-9a-zA-Z_]*&quot;
	# test comment : &quot;&quot;
 	 str : &quot;&quot;[^&quot;]*&quot;&quot; .a


comment : &quot;#.*&quot;&quot;##</span>;

	<span class="attribute">#[<span class="ident">test</span>]</span>
	<span class="attribute">#[<span class="ident">should_panic</span>]</span>
	<span class="kw">fn</span> <span class="ident">test_scan_non_space_past_regex</span>() {
		<span class="ident">print_err</span>(<span class="ident">scan</span>(<span class="ident">TEST_DOC_FAIL_REGFMT</span>)).<span class="ident">unwrap</span>();
	}

	<span class="kw">const</span> <span class="ident">TEST_DOC_INVALID_REGX</span>: <span class="kw-2">&amp;</span><span class="ident">str</span> <span class="op">=</span> <span class="string">r##&quot;
name : &quot;[a-zA-Z_][0-9a-zA-Z_]*&quot;
	# test comment : &quot;&quot;
 	 str : &quot;&quot;[^&quot;]*&quot;&quot;


comment : &quot;*#.*\]&quot;&quot;##</span>;

	<span class="attribute">#[<span class="ident">test</span>]</span>
	<span class="attribute">#[<span class="ident">should_panic</span>]</span>
	<span class="kw">fn</span> <span class="ident">test_scan_invalid_regex</span>() {
		<span class="ident">print_err</span>(<span class="ident">scan</span>(<span class="ident">TEST_DOC_INVALID_REGX</span>)).<span class="ident">unwrap</span>();
	}

	<span class="kw">const</span> <span class="ident">TEST_DOC_DUPLICATE_NAME</span>: <span class="kw-2">&amp;</span><span class="ident">str</span> <span class="op">=</span> <span class="string">r##&quot;
name : &quot;[a-zA-Z_][0-9a-zA-Z_]*&quot;
	# test comment : &quot;&quot;
 	 str : &quot;&quot;[^&quot;]*&quot;&quot;


name : &quot;#.*&quot;&quot;##</span>;

	<span class="attribute">#[<span class="ident">test</span>]</span>
	<span class="attribute">#[<span class="ident">should_panic</span>]</span>
	<span class="kw">fn</span> <span class="ident">test_scan_duplicate_names</span>() {
		<span class="ident">print_err</span>(<span class="ident">scan</span>(<span class="ident">TEST_DOC_DUPLICATE_NAME</span>)).<span class="ident">unwrap</span>();
	}

	<span class="kw">const</span> <span class="ident">TEST_DOC_EMPTY_REGEX_MATCH</span>: <span class="kw-2">&amp;</span><span class="ident">str</span> <span class="op">=</span> <span class="string">r##&quot;
name : &quot;a?|[a-zA-Z_][0-9a-zA-Z_]*&quot;
	# test comment : &quot;&quot;  
 	 str : &quot;&quot;[^&quot;]*&quot;&quot;	


comment : &quot;#.*&quot;
&quot;##</span>;

	<span class="attribute">#[<span class="ident">test</span>]</span>
	<span class="attribute">#[<span class="ident">should_panic</span>]</span>
	<span class="kw">fn</span> <span class="ident">test_scan_empty_regex_match</span>() {
		<span class="ident">print_err</span>(<span class="ident">scan</span>(<span class="ident">TEST_DOC_EMPTY_REGEX_MATCH</span>)).<span class="ident">unwrap</span>();
	}
}

<span class="kw">mod</span> <span class="ident">build_script</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">build_script</span>::{<span class="ident">build_lexer</span>, <span class="ident">LexerBuilder</span>};
<span class="comment">// also contains &#39;lexer!&#39;</span>
</code></pre></div>
</section><section id="search" class="content hidden"></section><div id="rustdoc-vars" data-root-path="../../" data-current-crate="lex" data-search-index-js="../../search-index.js" data-search-js="../../search.js"></div>
</body></html>